# 模型支持的列表以及下载地址
后处理是直接扣的 [ax-samples](https://github.com/AXERA-TECH/ax-samples)，后续可能会添加一些开源的车牌识别、人体姿态的多级模型示例代码，不好合到主线的也可能在分支实现（画饼）。

|模型|[枚举值](../examples/sample_run_joint/sample_run_joint_post_process.h)|下载地址|配置文件(有则表示主线已经支持)|备注|
|-|-|-|-|-|
|yolov5|17 ```MT_DET_YOLOV5```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov5s.joint) / [nv12](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov5s-face.joint)|[yolov5s.json](../examples/sample_run_joint/config/yolov5s.json)|[如何更换自己训练的 yolov5 模型](../docs/how_to_deploy_custom_yolov5_model.md)|
|yolov5-face|```MT_DET_YOLOV5_FACE```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov5s.joint) / [nv12](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov5s_face_nv12_11.joint)|[yolov5s_face.json](../examples/sample_run_joint/config/yolov5s_face.json)|[yolov5-face](https://github.com/deepcam-cn/yolov5-face)|
|yolov5-seg|```MT_INSEG_YOLOV5_MASK```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov5s-seg.joint)|[yolov5_seg.json](../examples/sample_run_joint/config/yolov5_seg.json)|~~有内存泄漏，cv::Mat指针无法delete，但是可以release，泄露几个小时演示一下是没问题的~~ ***修好了***|
|yolov7|```MT_DET_YOLOV7```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov7-tiny.joint)|[yolov7.json](../examples/sample_run_joint/config/yolov7.json)|-|
|yolox|```MT_DET_YOLOX```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolox_s.joint)|[yolox.json](../examples/sample_run_joint/config/yolox.json)|-|
|nanodet|```MT_DET_NANODET```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/nanom.joint)|[nanodet.json](../examples/sample_run_joint/config/nanodet.json)|需要改很多东西，模型转换可能比较困难|
|pp-human-seg|```MT_SEG_PPHUMSEG```|[bgr](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/pp_human_seg_mobile_sim.joint) / [nv12](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/pp_human_seg_mobile_sim_nv12.joint)|[pp_human_seg.json](../examples/sample_run_joint/config/pp_human_seg.json)|~~在 [fork的分支](https://github.com/ZHEQIUSHUI/ax-pipeline/tree/pphumseg) 实现了，但是只在```sample_vin_ivps_joint_vo```实现了，暂时不好合到主线，可能是以后的kpi，未来可期~~ ***主线已支持***|
|hrnet-human-pose|```MT_MLM_HUMAN_POSE_HRNET```|[yolov5s](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/yolov5s.joint) [hrnet](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/hrnet_256x192.joint)|[hrnet_pose.json](../examples/sample_run_joint/config/hrnet_pose.json)|前置通过yolov5s检测，抠图进行人体姿态检测。暂时有bug，已经push同事在帮忙修，将就先用。允许两个模型不同格式串联使用~~两个模型暂时必须为相同的 NV12/BGR/RGB 格式输入~~。|
|ax-person-det|```MT_DET_YOLOX_PPL```|[ax_person_det](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/ax_person_det.joint)|[ax_person_det.json](../examples/sample_run_joint/config/ax_person_det.json) |爱芯元智算法组训练的yolox人体检测模型开源版本|
|ax-human-pose|```MT_MLM_HUMAN_POSE_AXPPL```|[ax_person_det](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/ax_person_det.joint) [ax_pose](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/ax_pose.joint)|[ax_pose.json](../examples/sample_run_joint/config/ax_pose.json)|爱芯元智算法组训练的人体姿态开源版本，前置通过```ax-person-detection```检测人体，抠图进行人体姿态检测。允许两个模型不同格式串联使用~~两个模型暂时必须为相同的 NV12/BGR/RGB 格式输入~~。|
|palm-hand-detection|```MT_DET_PALM_HAND```|[palm_detection](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/palm_detection.joint)|[palm_hand_detection.json](../examples/sample_run_joint/config/palm_hand_detection.json)|mediepipe的人手检测模型，感谢 [FeiGeChuanShu](https://github.com/FeiGeChuanShu) 适配到爱芯派平台|
|hand-pose|```MT_MLM_HAND_POSE```|[palm_detection](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/palm_detection.joint) [handpose](https://github.com/AXERA-TECH/ax-models/raw/main/ax620/handpose.joint)|[hand_pose.json](../examples/sample_run_joint/config/hand_pose.json)|mediepipe的人手姿态模型，感谢 [FeiGeChuanShu](https://github.com/FeiGeChuanShu) 适配到爱芯派平台|
|yolopv2|```MT_DET_YOLOPV2```|-|[yolopv2.json](../examples/sample_run_joint/config/yolopv2.json)|感谢 [FeiGeChuanShu](https://github.com/FeiGeChuanShu) 适配到爱芯派平台|